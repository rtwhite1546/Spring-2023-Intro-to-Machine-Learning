{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4744962-cf2d-414d-acf8-38e56a8c5bea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MTH 4224 / CSE 4224 - Homework 3\n",
    "\n",
    "## Trees and Ensemble Models\n",
    "\n",
    "**Deadline**: Apr 23\n",
    "\n",
    "**Points**: 65\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Submit **one** Python notebook file for grading. Your file must include **text explanations** of your work, **well-commented code**, and the **outputs** from your code.\n",
    "\n",
    "### Datasets\n",
    "\n",
    "For problems 1-5, use the [Census Income Dataset](https://archive.ics.uci.edu/ml/datasets/Adult) of features of adults in the U.S. labeled with whether or not their income exceeds $50K/yr based on census data.\n",
    "\n",
    "For porblems 6-11, use the [Auto MPG Data Set](https://archive.ics.uci.edu/ml/datasets/Auto+MPG) of data city-cycle fuel consumption of various vehicles.\n",
    "\n",
    "### Problems\n",
    "\n",
    "#### Income Classification\n",
    "\n",
    "1. **[5 points]** Use pairplots to analyze the feature distributions and output labels. Note any strong patterns you observe.\n",
    "\n",
    "2. **[5 points]** Train a decision tree classifier to classify which people have incomes over $50k/year and test it on a test set.\n",
    "\n",
    "3. **[5 points]** Use cost-complexity pruning to simplify your tree as much as possible to maintain high validation accuracy and plot tree diagrams. Discuss what is intuitive (or not intuitive) about the trained model's decisionmaking process.\n",
    "\n",
    "4. **[5 points]** Tune either a random forest or XGBoost classifier, and justify your choice of 1 algorithm over the other.\n",
    "\n",
    "5. **[5 points]** Compute feature importance metrics by both mean decrease in impurity and by permutation importance. Which features do these two metrics and the plotted tree from Problem 2 agree are important? Does this seem practical?\n",
    "\n",
    "#### Fuel Economy Prediction\n",
    "\n",
    "6. **[5 points]** Perform automated exploratory data analysis using SweetViz (or a similar library). Note any strong relationships between features.\n",
    "\n",
    "7. **[5 points]** Apply 2D data visualization with PCA, MDS, and t-SNE. Plot the resulting 2D projection and color-code the points by MPG. Do you suspect the data naturally has a specific number of clusters?\n",
    "\n",
    "8. **[5 points]** Use K-Means clustering to dig deeper into the question of the ideal number of clusters of the data. Perform silhoutte analysis of your clusters.\n",
    "\n",
    "9. **[5 points]** Choose Gaussian mixture clustering or DBSCAN/OPTICS to perform clustering on the data. Argue why your choice of method is ideal for the data.\n",
    "\n",
    "10. **[10 points]** Train a separate XGBoost regressor to predict MPG for each cluster from your best clustering model. Measure the regression performance on each cluster.\n",
    "\n",
    "11. **[10 points]** Perform feature importance study on each trained models. Are different features important in different clusters? Discuss what is intuitive (or not intuitive) about the decisionmaking processes of the separate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf5cd03-e11d-4135-a545-e35ff128ebc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
